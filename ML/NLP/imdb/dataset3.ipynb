{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ff4d69-497a-4877-ac80-df8dea0b4d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "# отключение предупреждения\n",
    "\n",
    "#os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68fec7ad-6b6c-4e7d-85e0-79342d4704b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pathlib \n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959434c9-3024-4a8c-bd36-1537d6e96641",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "работаем на устройстве:  cuda\n",
      "Версия torch:            2.7.1+cu126\n",
      "версия  cuDNN:           91100\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(\"работаем на устройстве: \", DEVICE)\n",
    "print('Версия torch:           ', torch.__version__)\n",
    "print(\"версия  cuDNN:          \", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbee3b7e-b26b-4954-ab98-f9689b435ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/maksim/develops/python/projects/ML/NLP/imdb'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Текущее положение\n",
    "path_1 = os.getcwd()\n",
    "path_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f66edc3e-70cc-4548-b5dd-25296e27e1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Пути к директориям с данными\n",
    "\n",
    "train_dir_1 = os.path.join(path_1, 'dataset2/train/')\n",
    "test_dir_1 = os.path.join(path_1, 'dataset2/test/')\n",
    "\n",
    "train_dir_2 = os.path.join(path_1, 'dataset3/train/')\n",
    "\n",
    "dataset_new = os.path.join(path_1, 'data/dataset_new/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83ad8a41-b13c-47a8-a857-e4a8131ba03b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Расположение файла для кодировки слов\n",
    "path_vocab = 'imdb.vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f086f-64ee-4412-844b-ee07c9c2a19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525fad98-e957-4d35-aec2-dca4718893bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698f1a7-96d6-4786-ba2f-c287e0df5cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "train_directory_1 = train_dir_1\n",
    "train_directory_2 = train_dir_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4954d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего отзывов: 42927\n",
      "Пример номера метки и длины текста: 1, 110\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils.utils import transform_text\n",
    "\n",
    "def load_dataset(base_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    # Предположим, что каждая папка — это рейтинг, например \"1\", \"2\", ..., \"10\"\n",
    "    for rating_folder in os.listdir(base_path):\n",
    "        folder_path = os.path.join(base_path, rating_folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for filename in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                if os.path.isfile(file_path):\n",
    "                    # Преобразуем текст файла в числовой вектор\n",
    "                    vector = transform_text(file_path, path_vocab)  # ваша функция преобразования\n",
    "                    data.append(vector)\n",
    "                    labels.append(int(rating_folder))  # метка - рейтинг из имени папки\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "# Загрузка данных\n",
    "base_path = dataset_new\n",
    "data, labels = load_dataset(base_path)\n",
    "\n",
    "# Теперь можно использовать data и labels для обучения модели\n",
    "# Например, вывести размеры\n",
    "print(f\"Всего отзывов: {len(data)}\")\n",
    "print(f\"Пример номера метки и длины текста: {labels[0]}, {len(data[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "538b265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отзыв #1:\n",
      "Вектор: [569, 8, 1, 747, 2992, 0, 0, 9, 12, 2165, 51, 9, 1202, 55, 3558, 14, 0, 250, 108, 1, 0, 2, 109, 3, 0, 9, 842, 5, 65, 85, 4, 29, 3, 811, 0, 2862, 4963, 0, 60, 6350, 25191, 8, 4436, 74439, 2, 1, 4408, 195, 0, 653, 2, 0, 35, 3, 1446, 0, 0, 9, 216, 304, 1, 16, 8, 1, 0, 1, 1024, 12, 2095, 0, 216, 29, 102, 68, 0, 1, 10864, 772, 91, 1838, 1, 2046, 53, 0, 0, 13, 1165, 17655, 1042, 8, 24, 0, 8, 1, 128, 21, 89, 0, 582, 126, 0, 582, 126, 0, 2202, 154, 0, 0, 0, 88467]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #2:\n",
      "Вектор: [3065, 14, 109, 0, 5, 21, 31, 1, 3507, 300, 745, 485, 5607, 0, 0, 6, 54, 50, 4, 3, 2055, 2057, 41, 35, 109, 21692, 15, 0, 10, 623, 907, 4, 3, 18, 497, 130, 15, 3, 6586, 833, 2, 259, 326, 4348, 35, 0, 3, 0, 507, 5, 26, 984, 360, 8, 5292, 3044, 23, 1, 3981, 4, 10, 3112, 0, 0, 7587, 44, 607, 130, 19, 3, 952, 1155, 202, 182, 0, 36, 52, 1026, 5, 14115, 2271, 5, 9103, 36, 34, 67, 1097, 1, 3134, 0, 9, 253, 115, 11, 39, 2327, 271, 14, 1735, 5, 138, 12, 83, 22, 66, 304, 48, 9429, 30, 338, 11, 52, 199, 22, 229, 0, 52, 7081, 93, 57, 2, 16235, 99, 87, 135, 22, 5452, 0, 12115, 11, 39, 116, 2053, 59, 26, 5, 2271, 5, 1, 79, 503, 4, 1, 1111, 240, 71, 661, 24, 2793, 0, 9, 5858, 5, 256, 11, 3, 360, 569, 8, 137, 3, 37672, 2884, 13, 8923, 68, 4869, 4, 1, 2004, 4, 6368, 0, 0, 0, 57, 352, 10, 0, 1, 16, 6, 3721, 0, 17, 783, 10, 0, 10, 6, 114, 7, 497, 5, 75, 0, 52, 206, 5, 9103, 2, 51, 52, 186, 163, 39, 601, 52, 206, 48, 4305, 2, 1950, 39, 434, 5, 13525, 42, 86, 5006, 7, 29, 0, 10, 235, 6, 20, 32, 207, 0, 2, 52, 6, 388, 20, 3, 1124, 6457, 0, 14, 2511, 45, 0, 52, 6, 32, 31380, 0, 3, 23318, 19952, 237, 603, 10234, 561, 6, 233, 1707, 5, 8161, 39, 3313, 6074, 45, 4, 1, 1568, 51, 52, 206, 78611, 190, 5, 6155, 1593, 1, 8595, 303, 3, 6732, 2, 3098, 1047, 45, 19, 1, 0, 0, 0, 206, 3, 5809, 11, 39, 7587, 6, 8, 1196, 0, 36, 0, 0, 468, 4031, 38, 5, 75, 0, 276, 0, 10, 6406, 1239, 0, 167, 5, 138, 81, 1, 2630, 31, 0, 15498, 45, 1, 2419, 2778, 2, 2180, 39, 329, 5972, 0, 52, 888, 130, 3, 894, 42, 1, 2298, 4, 167, 8, 0, 92, 5410, 45, 292, 83, 52, 638, 45, 11, 38, 23, 3252, 167, 0, 0, 111, 293, 225, 42, 0, 0, 0, 6, 27, 212, 114, 2727, 2, 48, 3852, 11, 52, 1785, 57, 15, 1472, 10, 642, 2742, 617, 3, 2963, 11, 6, 3038, 4, 2123, 322, 2, 3038, 4, 2123, 617, 2, 9230, 31, 106, 31, 0, 0, 38, 23, 3001, 4, 1609, 1383, 4, 1940, 3120, 288, 15, 0, 2, 131, 6651, 1153, 5, 1472, 129, 0, 20, 61, 121, 7, 20868, 479, 1, 3332, 4, 1, 0, 17, 2727, 985, 5, 778, 130, 4, 0, 1402, 3038, 4, 2123, 2, 5040, 19, 39, 142, 8, 1, 1955, 1783, 0, 292, 52, 9498, 1, 0, 1070, 7, 130, 0, 440, 267, 7, 12, 61, 3, 0, 30, 217, 52, 274, 32928, 12383, 19, 39, 0, 0, 0, 6, 355, 602, 42, 10, 78757, 78, 16, 6, 11, 34, 54, 1269, 5, 27337, 3, 1856, 230, 45, 4, 1, 6361, 1006, 291, 0, 3, 146, 6457, 1435, 0, 38, 6, 3, 170, 4, 1957, 42, 32, 23133, 30, 1, 128, 4, 1, 0, 114, 70, 876, 32, 20059, 4167, 2048, 0, 51, 70, 85, 876, 0, 44, 137, 3, 4020, 1146, 11, 22, 7514, 24, 0, 37, 22, 1239, 0, 8, 3, 0, 0, 92, 292, 22, 2246, 37, 48, 224, 34, 1840, 130, 1, 1884, 4, 12039, 0, 0, 0, 0, 309, 300, 23, 0, 1, 745, 11, 807, 21, 5607, 0, 31, 1, 53, 187, 11, 34, 68, 557, 15, 0, 12, 317, 167, 141, 1, 0, 2791, 288, 48, 57205, 2, 1380, 278, 0, 9, 25, 5, 256, 83, 34, 41, 66, 157, 124, 5, 0, 1, 62, 6, 8810, 0, 2, 13112, 0, 33, 107, 79, 848, 6337, 22386, 13, 1, 61, 271, 5, 65, 1, 0, 149, 266, 1, 3547, 752, 81, 39, 0, 267, 52, 199, 1, 3507, 300, 745, 485, 5607, 251, 96, 39085, 48, 1222, 81, 10, 0, 0, 0, 337, 86, 231, 1984, 0, 267, 34, 199, 34, 0, 0, 0, 0, 96, 30, 217, 25, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #3:\n",
      "Вектор: [1626, 0, 10, 6, 27, 272, 184, 16, 11, 21, 177, 5, 761, 2, 10, 257, 35, 27, 642, 3178, 1854, 0, 1, 5041, 171, 6, 11, 0, 0, 4, 3, 84, 0, 1, 85, 171, 4, 10, 16, 121, 32, 3093, 283, 4, 937, 57, 1, 102, 2, 1, 158, 621, 195, 6808, 2, 1, 237, 0, 1506, 5, 0, 1, 4135, 5, 10, 16, 29, 727, 11, 52, 6, 0, 0, 143, 717, 157, 238, 51, 9, 132, 11, 1, 18, 12146, 81, 32, 216, 3954, 907, 99, 0, 0, 816, 1, 153, 12, 258, 5, 0, 29, 22, 2797, 8, 383, 6, 245, 1, 296, 1181, 0, 0, 6988, 2, 5223, 1924, 819, 14, 1, 362, 8458, 13, 6808, 4059, 184, 1, 0, 131, 1924, 23, 36, 7475, 2, 7452, 11, 29, 34, 82, 6, 5, 15654, 21, 45, 4, 1, 0, 143, 242, 1, 153, 199, 11, 10, 4227, 94, 5, 980, 1, 62, 20100, 3, 633, 8, 0, 103, 2, 20100, 11, 3, 262, 16, 12, 5, 0, 0, 22, 12, 0, 1, 16, 11, 1419, 12, 574, 2, 6472, 0, 1, 918, 4, 60, 6, 3, 2196, 270, 11, 4886, 54, 1, 482, 85, 5349, 226, 4, 1, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #4:\n",
      "Вектор: [0, 155, 101, 0, 0, 8, 11, 404, 29, 21, 25, 5, 82, 6, 758, 0, 231, 238, 35, 0, 21, 3350, 120, 3, 0, 13, 0, 41, 1, 22596, 1104, 0, 1170, 15, 412, 56, 1607, 1082, 0, 1, 112, 6, 556, 0, 1, 102, 23, 19376, 0, 1, 42926, 6, 15333, 2, 1, 218, 150, 6, 41, 1017, 0, 13, 21, 67, 12888, 35, 1, 411, 0, 10, 18, 6, 1376, 1598, 31, 0, 127, 120, 46, 21, 118, 227, 0, 13, 1, 665, 189, 263, 8, 3, 707, 937, 2, 1, 0, 4373, 23, 1264, 0, 134, 244, 59, 177, 5, 2041, 965, 35, 2533, 37, 0, 6, 3, 574, 718, 5, 0, 0, 30, 217, 11, 18, 96, 8370, 19, 1, 3611, 9123, 4, 1961, 115, 0, 3061, 1, 505, 8, 10, 2533, 0, 935, 35, 0, 80, 1856, 0, 27, 318, 99, 1, 127, 13701, 568, 4, 39, 0, 8502, 0, 39, 158, 12895, 1418, 2, 691, 79, 16411, 1154, 1478, 138, 5, 4007, 5, 1097, 64, 3597, 986, 3134, 8, 3, 3757, 2535, 0, 1, 435, 1427, 91, 3, 815, 29, 0, 17, 148, 22, 1116, 1, 13853, 5, 4007, 2, 497, 14024, 93, 1796, 1162, 485, 1, 7615, 721, 13, 48, 426, 4, 952, 0, 21, 63, 89, 348, 5, 26, 3, 80846, 8, 639, 5, 910, 801, 45, 60, 392, 5785, 485, 1, 22423, 623, 2280, 2, 1, 0, 989, 5, 266, 21, 19, 1, 347, 1392, 23, 2556, 0, 228, 1, 112, 6, 36, 0, 88, 4, 1, 18, 6, 2776, 4748, 0, 564, 1, 4542, 2052, 2745, 1, 4710, 39571, 547, 1152, 2, 1, 0, 3017, 2935, 33, 181, 5, 25, 3, 928, 578, 5, 0, 1, 568, 5252, 570, 130, 278, 0, 21, 766, 7, 51, 11, 0, 38, 209, 54, 98, 2101, 0, 5, 343, 2, 21, 124, 89, 75, 69, 628, 19, 1, 482, 4, 1, 0, 2210, 141, 585, 37, 10, 61, 162, 21, 889, 11, 1, 1843, 1048, 4, 1, 0, 7446, 6, 798, 14, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #5:\n",
      "Вектор: [1, 721, 4, 10, 16, 6, 0, 6, 50, 667, 71, 0, 83309, 13834, 6, 408, 5, 26, 1, 0, 0, 17, 1, 159, 150, 6, 11, 0, 20, 30, 29, 1524, 0, 0, 3, 170, 50, 1503, 71, 5686, 0, 1, 434, 33, 261, 37, 3, 0, 0, 0, 59, 10, 16, 161, 43, 1, 0, 0, 12, 63, 0, 51, 77, 333, 613, 15, 10, 0, 0, 0, 55, 0, 451, 1, 721, 11, 7, 474, 5, 0, 10, 16, 6, 317, 0, 0, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Просмотр первых нескольких примеров\n",
    "for i in range(5):  # первые 5 отзывов\n",
    "    print(f\"Отзыв #{i+1}:\")\n",
    "    print(\"Вектор:\", data[i])\n",
    "    print(\"Метка (рейтинг):\", labels[i])\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db6d30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Допустим, data - список с векторами, labels - список меток\n",
    "with open('data/dataset.pkl', 'wb') as f:\n",
    "    pickle.dump((data, labels), f)\n",
    "\n",
    "# Загрузка датасета из файла\n",
    "with open('data/dataset.pkl', 'rb') as f:\n",
    "    data_loaded, labels_loaded = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5664fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отзыв #1:\n",
      "Вектор: [569, 8, 1, 747, 2992, 0, 0, 9, 12, 2165, 51, 9, 1202, 55, 3558, 14, 0, 250, 108, 1, 0, 2, 109, 3, 0, 9, 842, 5, 65, 85, 4, 29, 3, 811, 0, 2862, 4963, 0, 60, 6350, 25191, 8, 4436, 74439, 2, 1, 4408, 195, 0, 653, 2, 0, 35, 3, 1446, 0, 0, 9, 216, 304, 1, 16, 8, 1, 0, 1, 1024, 12, 2095, 0, 216, 29, 102, 68, 0, 1, 10864, 772, 91, 1838, 1, 2046, 53, 0, 0, 13, 1165, 17655, 1042, 8, 24, 0, 8, 1, 128, 21, 89, 0, 582, 126, 0, 582, 126, 0, 2202, 154, 0, 0, 0, 88467]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #2:\n",
      "Вектор: [3065, 14, 109, 0, 5, 21, 31, 1, 3507, 300, 745, 485, 5607, 0, 0, 6, 54, 50, 4, 3, 2055, 2057, 41, 35, 109, 21692, 15, 0, 10, 623, 907, 4, 3, 18, 497, 130, 15, 3, 6586, 833, 2, 259, 326, 4348, 35, 0, 3, 0, 507, 5, 26, 984, 360, 8, 5292, 3044, 23, 1, 3981, 4, 10, 3112, 0, 0, 7587, 44, 607, 130, 19, 3, 952, 1155, 202, 182, 0, 36, 52, 1026, 5, 14115, 2271, 5, 9103, 36, 34, 67, 1097, 1, 3134, 0, 9, 253, 115, 11, 39, 2327, 271, 14, 1735, 5, 138, 12, 83, 22, 66, 304, 48, 9429, 30, 338, 11, 52, 199, 22, 229, 0, 52, 7081, 93, 57, 2, 16235, 99, 87, 135, 22, 5452, 0, 12115, 11, 39, 116, 2053, 59, 26, 5, 2271, 5, 1, 79, 503, 4, 1, 1111, 240, 71, 661, 24, 2793, 0, 9, 5858, 5, 256, 11, 3, 360, 569, 8, 137, 3, 37672, 2884, 13, 8923, 68, 4869, 4, 1, 2004, 4, 6368, 0, 0, 0, 57, 352, 10, 0, 1, 16, 6, 3721, 0, 17, 783, 10, 0, 10, 6, 114, 7, 497, 5, 75, 0, 52, 206, 5, 9103, 2, 51, 52, 186, 163, 39, 601, 52, 206, 48, 4305, 2, 1950, 39, 434, 5, 13525, 42, 86, 5006, 7, 29, 0, 10, 235, 6, 20, 32, 207, 0, 2, 52, 6, 388, 20, 3, 1124, 6457, 0, 14, 2511, 45, 0, 52, 6, 32, 31380, 0, 3, 23318, 19952, 237, 603, 10234, 561, 6, 233, 1707, 5, 8161, 39, 3313, 6074, 45, 4, 1, 1568, 51, 52, 206, 78611, 190, 5, 6155, 1593, 1, 8595, 303, 3, 6732, 2, 3098, 1047, 45, 19, 1, 0, 0, 0, 206, 3, 5809, 11, 39, 7587, 6, 8, 1196, 0, 36, 0, 0, 468, 4031, 38, 5, 75, 0, 276, 0, 10, 6406, 1239, 0, 167, 5, 138, 81, 1, 2630, 31, 0, 15498, 45, 1, 2419, 2778, 2, 2180, 39, 329, 5972, 0, 52, 888, 130, 3, 894, 42, 1, 2298, 4, 167, 8, 0, 92, 5410, 45, 292, 83, 52, 638, 45, 11, 38, 23, 3252, 167, 0, 0, 111, 293, 225, 42, 0, 0, 0, 6, 27, 212, 114, 2727, 2, 48, 3852, 11, 52, 1785, 57, 15, 1472, 10, 642, 2742, 617, 3, 2963, 11, 6, 3038, 4, 2123, 322, 2, 3038, 4, 2123, 617, 2, 9230, 31, 106, 31, 0, 0, 38, 23, 3001, 4, 1609, 1383, 4, 1940, 3120, 288, 15, 0, 2, 131, 6651, 1153, 5, 1472, 129, 0, 20, 61, 121, 7, 20868, 479, 1, 3332, 4, 1, 0, 17, 2727, 985, 5, 778, 130, 4, 0, 1402, 3038, 4, 2123, 2, 5040, 19, 39, 142, 8, 1, 1955, 1783, 0, 292, 52, 9498, 1, 0, 1070, 7, 130, 0, 440, 267, 7, 12, 61, 3, 0, 30, 217, 52, 274, 32928, 12383, 19, 39, 0, 0, 0, 6, 355, 602, 42, 10, 78757, 78, 16, 6, 11, 34, 54, 1269, 5, 27337, 3, 1856, 230, 45, 4, 1, 6361, 1006, 291, 0, 3, 146, 6457, 1435, 0, 38, 6, 3, 170, 4, 1957, 42, 32, 23133, 30, 1, 128, 4, 1, 0, 114, 70, 876, 32, 20059, 4167, 2048, 0, 51, 70, 85, 876, 0, 44, 137, 3, 4020, 1146, 11, 22, 7514, 24, 0, 37, 22, 1239, 0, 8, 3, 0, 0, 92, 292, 22, 2246, 37, 48, 224, 34, 1840, 130, 1, 1884, 4, 12039, 0, 0, 0, 0, 309, 300, 23, 0, 1, 745, 11, 807, 21, 5607, 0, 31, 1, 53, 187, 11, 34, 68, 557, 15, 0, 12, 317, 167, 141, 1, 0, 2791, 288, 48, 57205, 2, 1380, 278, 0, 9, 25, 5, 256, 83, 34, 41, 66, 157, 124, 5, 0, 1, 62, 6, 8810, 0, 2, 13112, 0, 33, 107, 79, 848, 6337, 22386, 13, 1, 61, 271, 5, 65, 1, 0, 149, 266, 1, 3547, 752, 81, 39, 0, 267, 52, 199, 1, 3507, 300, 745, 485, 5607, 251, 96, 39085, 48, 1222, 81, 10, 0, 0, 0, 337, 86, 231, 1984, 0, 267, 34, 199, 34, 0, 0, 0, 0, 96, 30, 217, 25, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #3:\n",
      "Вектор: [1626, 0, 10, 6, 27, 272, 184, 16, 11, 21, 177, 5, 761, 2, 10, 257, 35, 27, 642, 3178, 1854, 0, 1, 5041, 171, 6, 11, 0, 0, 4, 3, 84, 0, 1, 85, 171, 4, 10, 16, 121, 32, 3093, 283, 4, 937, 57, 1, 102, 2, 1, 158, 621, 195, 6808, 2, 1, 237, 0, 1506, 5, 0, 1, 4135, 5, 10, 16, 29, 727, 11, 52, 6, 0, 0, 143, 717, 157, 238, 51, 9, 132, 11, 1, 18, 12146, 81, 32, 216, 3954, 907, 99, 0, 0, 816, 1, 153, 12, 258, 5, 0, 29, 22, 2797, 8, 383, 6, 245, 1, 296, 1181, 0, 0, 6988, 2, 5223, 1924, 819, 14, 1, 362, 8458, 13, 6808, 4059, 184, 1, 0, 131, 1924, 23, 36, 7475, 2, 7452, 11, 29, 34, 82, 6, 5, 15654, 21, 45, 4, 1, 0, 143, 242, 1, 153, 199, 11, 10, 4227, 94, 5, 980, 1, 62, 20100, 3, 633, 8, 0, 103, 2, 20100, 11, 3, 262, 16, 12, 5, 0, 0, 22, 12, 0, 1, 16, 11, 1419, 12, 574, 2, 6472, 0, 1, 918, 4, 60, 6, 3, 2196, 270, 11, 4886, 54, 1, 482, 85, 5349, 226, 4, 1, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #4:\n",
      "Вектор: [0, 155, 101, 0, 0, 8, 11, 404, 29, 21, 25, 5, 82, 6, 758, 0, 231, 238, 35, 0, 21, 3350, 120, 3, 0, 13, 0, 41, 1, 22596, 1104, 0, 1170, 15, 412, 56, 1607, 1082, 0, 1, 112, 6, 556, 0, 1, 102, 23, 19376, 0, 1, 42926, 6, 15333, 2, 1, 218, 150, 6, 41, 1017, 0, 13, 21, 67, 12888, 35, 1, 411, 0, 10, 18, 6, 1376, 1598, 31, 0, 127, 120, 46, 21, 118, 227, 0, 13, 1, 665, 189, 263, 8, 3, 707, 937, 2, 1, 0, 4373, 23, 1264, 0, 134, 244, 59, 177, 5, 2041, 965, 35, 2533, 37, 0, 6, 3, 574, 718, 5, 0, 0, 30, 217, 11, 18, 96, 8370, 19, 1, 3611, 9123, 4, 1961, 115, 0, 3061, 1, 505, 8, 10, 2533, 0, 935, 35, 0, 80, 1856, 0, 27, 318, 99, 1, 127, 13701, 568, 4, 39, 0, 8502, 0, 39, 158, 12895, 1418, 2, 691, 79, 16411, 1154, 1478, 138, 5, 4007, 5, 1097, 64, 3597, 986, 3134, 8, 3, 3757, 2535, 0, 1, 435, 1427, 91, 3, 815, 29, 0, 17, 148, 22, 1116, 1, 13853, 5, 4007, 2, 497, 14024, 93, 1796, 1162, 485, 1, 7615, 721, 13, 48, 426, 4, 952, 0, 21, 63, 89, 348, 5, 26, 3, 80846, 8, 639, 5, 910, 801, 45, 60, 392, 5785, 485, 1, 22423, 623, 2280, 2, 1, 0, 989, 5, 266, 21, 19, 1, 347, 1392, 23, 2556, 0, 228, 1, 112, 6, 36, 0, 88, 4, 1, 18, 6, 2776, 4748, 0, 564, 1, 4542, 2052, 2745, 1, 4710, 39571, 547, 1152, 2, 1, 0, 3017, 2935, 33, 181, 5, 25, 3, 928, 578, 5, 0, 1, 568, 5252, 570, 130, 278, 0, 21, 766, 7, 51, 11, 0, 38, 209, 54, 98, 2101, 0, 5, 343, 2, 21, 124, 89, 75, 69, 628, 19, 1, 482, 4, 1, 0, 2210, 141, 585, 37, 10, 61, 162, 21, 889, 11, 1, 1843, 1048, 4, 1, 0, 7446, 6, 798, 14, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #5:\n",
      "Вектор: [1, 721, 4, 10, 16, 6, 0, 6, 50, 667, 71, 0, 83309, 13834, 6, 408, 5, 26, 1, 0, 0, 17, 1, 159, 150, 6, 11, 0, 20, 30, 29, 1524, 0, 0, 3, 170, 50, 1503, 71, 5686, 0, 1, 434, 33, 261, 37, 3, 0, 0, 0, 59, 10, 16, 161, 43, 1, 0, 0, 12, 63, 0, 51, 77, 333, 613, 15, 10, 0, 0, 0, 55, 0, 451, 1, 721, 11, 7, 474, 5, 0, 10, 16, 6, 317, 0, 0, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/dataset.pkl', 'rb') as f:\n",
    "    data_loaded, labels_loaded = pickle.load(f)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Отзыв #{i+1}:\")\n",
    "    print(\"Вектор:\", data_loaded[i])\n",
    "    print(\"Метка (рейтинг):\", labels_loaded[i])\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef0b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14437a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
      "89527\n",
      "39998\n",
      "Минимальный размер класса: 4151\n",
      "Датасет сохранён в 'balanced_dataset.pkl'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# функция загрузки словаря для кодировки слов из файла\n",
    "def vocab_read(path_vocab):\n",
    "    with open(path_vocab, \"r\") as f1:\n",
    "        line = f1.read().splitlines()\n",
    "    return line\n",
    "\n",
    "# загрузка словаря и просмотр первых 10 слов\n",
    "vocab = vocab_read(path_vocab)\n",
    "print(vocab[:10])\n",
    "n =len(vocab)\n",
    "print(n)\n",
    "vocab = vocab[:39998]\n",
    "print(len(vocab))\n",
    "\n",
    "\n",
    "# Параметры модели и тренировки\n",
    "input_size = len(vocab) + 2  # Предполагаемый размер словаря (число уникальных слов)\n",
    "\n",
    "hidden_size = 128\n",
    "num_classes = 8  # Два класса: положительный и отрицательный отзыв\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "len_text = 280  # длина текста (клоичество слов) используемая для оценки \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# vocab - список слов словаря\n",
    "# len_text - фиксированная длина текста (число слов)\n",
    "# base_path - папка с разбитыми по рейтингам папками и текстами\n",
    "\n",
    "def transform_text(text1, vocab, len_text, rand=False):\n",
    "    mass = [] \n",
    "    str1 =''    \n",
    "    fl = False\n",
    "    list_1 = [0, 1]  # из вашего кода, для rand\n",
    "\n",
    "    for ch in text1:\n",
    "        if len(mass) > len_text - 1:  # если слов больше чем нужно, выходим\n",
    "            return mass\n",
    "        if ch != ' ':\n",
    "            str1 = str1 + ch\n",
    "        if ch == ' ':\n",
    "            if str1 != '':                      \n",
    "                fl = False                                                            \n",
    "                for i in range(len(vocab)):\n",
    "                    if str1.lower() == vocab[i].lower():\n",
    "                        fl = True\n",
    "                        random_choice = random.choice(list_1)\n",
    "                        if rand == True and random_choice == 0:\n",
    "                            mass.append(1)  # РАНДОМНО заполняем единицей\n",
    "                            break\n",
    "                        mass.append(i + 2)\n",
    "                        str1 = ''\n",
    "                        break                                                 \n",
    "                if fl == False:  # если слово не найдено, заменяем нулями\n",
    "                    mass.append(0)\n",
    "                    str1 = ''        \n",
    "    # Проверка последнего слова\n",
    "    if str1 != '':\n",
    "        fl = False\n",
    "        for i in range(len(vocab)):\n",
    "            if str1.lower() == vocab[i].lower():\n",
    "                fl = True\n",
    "                mass.append(i + 2)\n",
    "                break                                                 \n",
    "        if fl == False:\n",
    "            mass.append(0)\n",
    "\n",
    "    # Дополнение нулями слева, если слов меньше заданной длины\n",
    "    while len(mass) < len_text:\n",
    "        mass.insert(0, 0)\n",
    "        \n",
    "    return mass\n",
    "\n",
    "\n",
    "def create_balanced_dataset(base_path, vocab, len_text, rand=False):\n",
    "    classes = [folder for folder in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, folder))]\n",
    "    class_counts = {}\n",
    "\n",
    "    # Считаем количество файлов в каждом классе\n",
    "    for cl in classes:\n",
    "        folder_path = os.path.join(base_path, cl)\n",
    "        count = len([name for name in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, name))])\n",
    "        class_counts[cl] = count\n",
    "\n",
    "    # Минимальный размер класса\n",
    "    min_count = min(class_counts.values())\n",
    "    print(f\"Минимальный размер класса: {min_count}\")\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for cl in classes:\n",
    "        folder_path = os.path.join(base_path, cl)\n",
    "        files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "        # Берём случайные (или первые) min_count файлов\n",
    "        if len(files) > min_count:\n",
    "            files = random.sample(files, min_count)\n",
    "        else:\n",
    "            files = files[:min_count]\n",
    "\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "            vec = transform_text(text, vocab, len_text, rand=rand)\n",
    "            data.append(vec)\n",
    "            labels.append(int(cl))  # если имя папки - число рейтинга\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "# Путь к папке с датасетом, словарь и длина текста должны быть определены\n",
    "base_path = dataset_new\n",
    "\n",
    "# vocab = [...]  # список слов вашего словаря\n",
    "len_text = 280  # например\n",
    "\n",
    "data, labels = create_balanced_dataset(base_path, vocab, len_text, rand=False)\n",
    "\n",
    "# Сохраняем в pickle\n",
    "with open('balanced_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump((data, labels), f)\n",
    "\n",
    "print(\"Датасет сохранён в 'balanced_dataset.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "512d85d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет успешно сохранён в 'dataset.pkl'\n",
      "Загружено отзывов: 33208\n",
      "Загружено меток: 33208\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Предположим, что у вас есть переменные:\n",
    "# data  — список векторов (числовых представлений отзывов)\n",
    "# labels — список меток (рейтингов)\n",
    "\n",
    "# Сохраняем в файл 'dataset.pkl'\n",
    "with open('dataset.pkl', 'wb') as f:\n",
    "    pickle.dump((data, labels), f)\n",
    "\n",
    "print(\"Датасет успешно сохранён в 'dataset.pkl'\")\n",
    "\n",
    "\n",
    "with open('dataset.pkl', 'rb') as f:\n",
    "    data_loaded, labels_loaded = pickle.load(f)\n",
    "\n",
    "\n",
    "print(f\"Загружено отзывов: {len(data_loaded)}\")\n",
    "print(f\"Загружено меток: {len(labels_loaded)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298e52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7f5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальное количество примеров на класс: 4151\n",
      "Сбалансированный датасет сохранён в 'balanced_dataset.pkl'\n",
      "Тестовый датасет сохранён в 'test_dataset.pkl'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "def transform_text(text1, vocab, len_text, rand=False):\n",
    "    mass = [] \n",
    "    str1 =''    \n",
    "    fl = False\n",
    "    list_1 = [0, 1]\n",
    "\n",
    "    for ch in text1:\n",
    "        if len(mass) > len_text - 1:\n",
    "            return mass\n",
    "        if ch != ' ':\n",
    "            str1 += ch\n",
    "        if ch == ' ':\n",
    "            if str1 != '':\n",
    "                fl = False\n",
    "                for i in range(len(vocab)):\n",
    "                    if str1.lower() == vocab[i].lower():\n",
    "                        fl = True\n",
    "                        random_choice = random.choice(list_1)\n",
    "                        if rand and random_choice == 0:\n",
    "                            mass.append(1)\n",
    "                            break\n",
    "                        mass.append(i + 2)\n",
    "                        str1 = ''\n",
    "                        break\n",
    "                if not fl:\n",
    "                    mass.append(0)\n",
    "                    str1 = ''\n",
    "    # Проверка последнего слова\n",
    "    if str1 != '':\n",
    "        fl = False\n",
    "        for i in range(len(vocab)):\n",
    "            if str1.lower() == vocab[i].lower():\n",
    "                fl = True\n",
    "                mass.append(i + 2)\n",
    "                break\n",
    "        if not fl:\n",
    "            mass.append(0)\n",
    "\n",
    "    while len(mass) < len_text:\n",
    "        mass.insert(0, 0)\n",
    "    return mass\n",
    "\n",
    "\n",
    "# def create_balanced_and_test_datasets(base_path, vocab, len_text, rand=False):\n",
    "#     classes = [folder for folder in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, folder))]\n",
    "#     class_counts = {}\n",
    "\n",
    "#     # Подсчёт количества файлов в каждом классе\n",
    "#     for cl in classes:\n",
    "#         folder_path = os.path.join(base_path, cl)\n",
    "#         count = len([name for name in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, name))])\n",
    "#         class_counts[cl] = count\n",
    "\n",
    "#     min_count = min(class_counts.values())\n",
    "#     print(f\"Минимальное количество примеров на класс: {min_count}\")\n",
    "\n",
    "#     balanced_data = []\n",
    "#     balanced_labels = []\n",
    "#     test_data = []\n",
    "#     test_labels = []\n",
    "\n",
    "#     for cl in classes:\n",
    "#         folder_path = os.path.join(base_path, cl)\n",
    "#         files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "#         random.shuffle(files)\n",
    "\n",
    "#         # Выбираем min_count файлов для сбалансированного датасета\n",
    "#         balanced_files = files[:min_count]\n",
    "#         # Остальные — для тестового датасета\n",
    "#         test_files = files[min_count:]\n",
    "\n",
    "#         # Обработка balanced\n",
    "#         for file_name in balanced_files:\n",
    "#             file_path = os.path.join(folder_path, file_name)\n",
    "#             with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#                 text = f.read()\n",
    "#             vec = transform_text(text, vocab, len_text, rand=rand)\n",
    "#             balanced_data.append(vec)\n",
    "#             balanced_labels.append(int(cl))\n",
    "\n",
    "#         # Обработка test\n",
    "#         for file_name in test_files:\n",
    "#             file_path = os.path.join(folder_path, file_name)\n",
    "#             with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#                 text = f.read()\n",
    "#             vec = transform_text(text, vocab, len_text, rand=rand)\n",
    "#             test_data.append(vec)\n",
    "#             test_labels.append(int(cl))\n",
    "\n",
    "#     return balanced_data, balanced_labels, test_data, test_labels\n",
    "\n",
    "\n",
    "# Путь к датасету\n",
    "base_path = dataset_new\n",
    "# vocab = [...]  # ваш список слов\n",
    "len_text = 280\n",
    "\n",
    "balanced_data, balanced_labels, test_data, test_labels = create_balanced_and_test_datasets(base_path, vocab, len_text, rand=False)\n",
    "\n",
    "# Сохраняем оба датасета по отдельности\n",
    "with open('balanced_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump((balanced_data, balanced_labels), f)\n",
    "\n",
    "with open('test_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump((test_data, test_labels), f)\n",
    "\n",
    "print(\"Сбалансированный датасет сохранён в 'balanced_dataset.pkl'\")\n",
    "print(\"Тестовый датасет сохранён в 'test_dataset.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5280cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv1(filename):\n",
    "    '''\n",
    "    Функция для получения рейтинга отзыва и номера (названия) файла по имени файла.\n",
    "    Ожидается, что имя файла имеет формат \"номер_рейтинг.txt\", например \"2429_1.txt\".\n",
    "    Возвращает кортеж: (рейтинг как строка, имя файла без расширения)\n",
    "    '''\n",
    "    # Убираем расширение файла\n",
    "    base_name = filename.split('.')[0]\n",
    "    # Разделяем по подчёркиванию\n",
    "    parts = base_name.split('_')\n",
    "    if len(parts) < 2:\n",
    "        return None, None  # Если формат некорректный\n",
    "    \n",
    "    rating = parts[-1]  # Рейтинг — часть после последнего подчёркивания\n",
    "    file_number = '_'.join(parts[:-1])  # Всё до рейтинга — номер файла (может содержать подчёркивания)\n",
    "    \n",
    "    return rating, file_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84c470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "2429\n"
     ]
    }
   ],
   "source": [
    "rating, file_num = inv1(\"2429_10.txt\")\n",
    "print(rating)   # '1'\n",
    "print(file_num) # '2429'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8347a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасеты успешно сохранены\n",
      "Сбалансированных примеров: 33208\n",
      "Тестовых примеров: 9719\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Допустим, у вас есть:\n",
    "# balanced_data, balanced_labels — сбалансированный датасет и метки\n",
    "# test_data, test_labels — тестовый датасет и метки\n",
    "\n",
    "# Сохраняем сбалансированный датасет\n",
    "with open('balanced_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump((balanced_data, balanced_labels), f)\n",
    "\n",
    "# Сохраняем тестовый датасет\n",
    "with open('test_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump((test_data, test_labels), f)\n",
    "\n",
    "print(\"Датасеты успешно сохранены\")\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Загружаем сбалансированный датасет\n",
    "with open('balanced_dataset.pkl', 'rb') as f:\n",
    "    balanced_data_loaded, balanced_labels_loaded = pickle.load(f)\n",
    "\n",
    "# Загружаем тестовый датасет\n",
    "with open('test_dataset.pkl', 'rb') as f:\n",
    "    test_data_loaded, test_labels_loaded = pickle.load(f)\n",
    "\n",
    "print(f\"Сбалансированных примеров: {len(balanced_data_loaded)}\")\n",
    "print(f\"Тестовых примеров: {len(test_data_loaded)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "544a8325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отзыв #1:\n",
      "Вектор: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 313, 0, 9765, 307, 7, 2, 0, 313, 3331, 17, 9, 2, 0, 0, 8, 64, 45, 158, 6, 83, 16, 2, 195, 290, 313, 3331, 101, 533, 49, 5, 2, 103, 24, 409, 6, 27, 2857, 6, 2, 103, 9, 2, 195, 2303, 3, 4913, 8890, 7, 9, 8, 0, 12, 225, 76, 125, 0, 0, 0, 7, 54, 114, 6, 6980, 11, 17, 0, 39, 682, 99, 160, 0, 2, 111, 7, 1291, 6, 0, 254, 2, 238, 16, 2, 0, 1147, 61, 902, 51, 38, 4, 0, 10117, 5, 4, 684, 236, 4441, 6, 27, 4, 11056, 32, 749, 2, 685, 0, 11, 17, 163, 70, 233, 38, 138, 33, 0, 135, 156, 10, 6629, 6, 4, 1155, 115, 1212, 260, 6, 796, 0, 1315, 207, 50, 0, 506, 4116, 190, 65, 1603, 131, 9, 0, 1315, 45, 13984, 20615, 383, 202, 2, 9003, 5, 5243, 3, 0, 3, 22, 68, 33277, 30, 130, 4, 0, 211, 4351, 202, 40, 0, 0, 11, 201, 45, 10151, 396, 6, 2, 1492, 5, 11420, 0, 268, 15, 2, 363, 0, 3583, 401, 987, 185, 3, 3599, 2605, 3226, 14, 2, 0, 144, 243, 35, 68, 42, 4603, 8, 9, 6, 2, 201, 32, 246, 25, 104, 0, 0, 1565, 277, 3939, 41, 140, 38, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #2:\n",
      "Вектор: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 13, 566, 11, 60, 27, 4, 703, 17, 283, 0, 10, 233, 12, 10, 13, 17157, 100, 308, 11, 4294, 0, 2, 113, 7, 4, 2437, 96, 5, 438, 106, 31, 0, 55, 2, 412, 7, 4, 190, 20, 155, 19, 44, 22, 68, 194, 2, 17, 12, 74, 0, 10, 235, 770, 6, 133, 12, 10, 13, 608, 6, 2, 0, 10, 563, 429, 127, 59, 20, 11, 0, 11, 17, 715, 6, 27, 4, 727, 5, 15031, 34, 184, 289, 3, 92, 4, 330, 314, 5, 4, 17, 20, 4, 2374, 16, 4, 4792, 0, 110, 9, 2, 696, 0, 10, 68, 1820, 4, 527, 19, 3, 11, 28, 975, 6, 27, 25104, 41, 0, 56, 0, 1225, 6, 4, 345, 38, 2, 0, 3305, 5, 2, 0, 20, 4, 2561, 5, 0, 6, 0, 55, 4, 0, 7, 110, 316, 6, 1131, 84, 11, 17, 0, 0, 5610, 5, 47, 0, 2, 1131, 349, 6, 759, 16, 65, 7417, 0, 44, 22, 83, 653, 2, 17, 572, 27, 1170, 9, 127, 0, 11, 28, 182, 6, 26, 75, 7041, 58, 3, 19031, 32, 4, 0, 39, 24, 4, 167, 34, 26, 109, 11, 15, 47, 8, 7, 3, 5476, 0, 0, 0, 10, 26, 6, 133, 11, 7, 28, 6, 27, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #3:\n",
      "Вектор: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 78, 139, 185, 9, 460, 14, 2, 319, 2, 17, 3504, 470, 2, 780, 1012, 0, 86, 35, 1366, 175, 6, 502, 2172, 0, 93, 35, 7041, 58, 2, 2832, 1690, 1142, 3, 149, 10302, 61, 7, 32, 232, 2, 242, 17, 5, 2, 0, 47, 7, 8, 0, 34, 2, 2246, 0, 91, 376, 5, 14102, 3, 4758, 16, 79, 0, 10, 206, 38, 6, 759, 3, 105, 2, 0, 18, 52, 11, 151, 13, 130, 10, 411, 76, 46, 5, 2, 17, 1644, 812, 0, 89, 5, 2, 297, 12, 6897, 2, 763, 12, 10, 13, 0, 404, 180, 74, 2, 169, 0, 5585, 69, 6381, 16, 247, 80, 14, 73, 14, 0, 0, 33, 1525, 3, 6634, 19, 12, 78, 96, 22, 233, 1525, 3, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #4:\n",
      "Вектор: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 362, 10, 215, 11, 1059, 52, 10, 13, 0, 41, 0, 56, 4399, 1597, 58, 2, 381, 5, 8, 15, 916, 31, 2, 0, 10, 362, 12, 8, 64, 0, 2, 113, 67, 57, 0, 10, 1747, 2, 1595, 12, 847, 0, 0, 23, 13, 37, 0, 6129, 3724, 25, 414, 131, 44, 23, 411, 164, 4, 0, 37, 0, 76, 130, 0, 2, 62, 50, 172, 3, 10, 90, 178, 6, 471, 11065, 13, 52, 2, 1595, 184, 317, 3, 1091, 31, 2, 0, 10, 1441, 56, 414, 131, 9, 17089, 84, 11, 1059, 2008, 37, 0, 2, 79, 1604, 7, 2, 1595, 24517, 3, 446, 4, 0, 10, 636, 23, 67, 2619, 0, 10, 102, 10, 55, 499, 2, 381, 5, 11, 6, 1733, 84, 10, 1747, 0, 57, 574, 35, 69, 3902, 8, 15, 916, 31, 2, 0, 44, 22, 26, 4, 484, 90, 273, 94, 105, 0, 35, 78, 234, 1006, 16, 70, 12, 8, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n",
      "Отзыв #5:\n",
      "Вектор: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 62, 122, 11, 17, 26, 4, 330, 0, 79, 0, 3, 375, 0, 91, 1960, 58, 4, 219, 159, 1223, 6, 0, 0, 0, 11, 19, 0, 4752, 24, 2, 0, 0, 951, 24, 2, 0, 0, 3, 1074, 0, 0, 0, 14913, 24, 9109, 3408, 0, 0, 0, 42, 574, 47, 60, 571, 44, 10, 92, 2, 2528, 169, 17, 16, 2, 2528, 169, 63, 359, 3, 0, 62, 10, 92, 8, 43, 0, 0, 0, 91, 50, 6, 401, 66, 0, 2151, 4070, 145, 322, 0, 0, 0, 182, 6, 1442, 0, 18, 105, 11, 19, 170, 3, 474, 7128, 31, 87, 35, 26, 964, 2, 159, 8566, 0, 0, 30, 5, 4, 2043, 91, 443, 1520, 34, 24, 2, 285, 1056, 5, 1336, 0, 3, 15467, 46, 15, 4, 1641, 0, 62, 0, 506, 26, 4, 0, 0, 57, 138, 151, 14, 4, 0, 443, 0, 0, 0, 24974, 70, 12, 35, 411, 96, 11, 19, 202, 718, 2, 12125, 1778, 9, 159, 8566, 4, 6132, 0, 44, 22, 102, 144, 0, 139, 105, 11, 0, 3, 66, 47, 22, 96, 5, 2, 0, 0, 42, 84, 0, 2203, 6, 662, 175, 0, 0, 9, 751, 0, 150, 373, 91, 0, 44, 10, 294, 1343, 322, 419, 613, 1888, 56, 0, 0, 0, 66, 11, 0, 90, 429, 127, 0, 90, 27, 0]\n",
      "Метка (рейтинг): 1\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/balanced_dataset.pkl', 'rb') as f:\n",
    "    data_loaded, labels_loaded = pickle.load(f)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Отзыв #{i+1}:\")\n",
    "    print(\"Вектор:\", data_loaded[i])\n",
    "    print(\"Метка (рейтинг):\", labels_loaded[i])\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a69dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0909d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c77cc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913774dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5eb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b466d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80faf468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9702682c-c953-40ff-9162-e4e7984e133a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this']\n",
      "89527\n",
      "39998\n"
     ]
    }
   ],
   "source": [
    "# функция загрузки словаря для кодировки слов из файла\n",
    "def vocab_read(path_vocab):\n",
    "    with open(path_vocab, \"r\") as f1:\n",
    "        line = f1.read().splitlines()\n",
    "    return line\n",
    "\n",
    "# загрузка словаря и просмотр первых 10 слов\n",
    "vocab = vocab_read(path_vocab)\n",
    "print(vocab[:10])\n",
    "n =len(vocab)\n",
    "print(n)\n",
    "vocab = vocab[:39998]\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9e71add-9a7c-4b67-bb42-93e50c948158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Параметры модели и тренировки\n",
    "input_size = len(vocab) + 2  # Предполагаемый размер словаря (число уникальных слов)\n",
    "\n",
    "hidden_size = 128\n",
    "num_classes = 8  # Два класса: положительный и отрицательный отзыв\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "len_text = 280  # длина текста (клоичество слов) используемая для оценки \n",
    "\n",
    "\n",
    "# Определение числа фолдов\n",
    "k_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a45810ef-de76-4e5f-8010-10a639f9d479",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05337601-bf87-4296-9b1e-7626403913a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d32a3bec-645e-4185-af82-84350bb14d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "list_1 = list(range(12))\n",
    "print(list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8ff2079-4e6f-4540-9abd-121cdcad0f78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# функция преобразования текста в числа\n",
    "\n",
    "def transform_text(text1, vocab=vocab, len_text=len_text, rand=False):\n",
    "    mass = [] \n",
    "    str1 =''    \n",
    "    for ch in text1:\n",
    "        if len(mass)>len_text-1: # если слов больше чем нужно, выходим\n",
    "            return mass\n",
    "        if ch !=' ':\n",
    "            str1 = str1 + ch\n",
    "        if ch ==' ':\n",
    "            if str1 !='':                      \n",
    "                fl = False                                                            \n",
    "                for i in range(len(vocab)):\n",
    "                    if str1.lower() == vocab[i].lower():\n",
    "                        fl = True\n",
    "                        random_choice = random.choice(list_1)\n",
    "                        if rand==True:\n",
    "                            if random_choice == 0:\n",
    "                                mass.append(1)  #  РАНДОМНО заполняем единицей\n",
    "                                break\n",
    "                        mass.append(i+2)\n",
    "                        str1 =''\n",
    "                        break                                                 \n",
    "                if fl == False: #  если слово не найдено, заменяем нулями\n",
    "                    mass.append(0)\n",
    "                    str1 =''        \n",
    "    for i in range(len(vocab)): # Проверяем последнее слово\n",
    "        if str1.lower() == vocab[i].lower():\n",
    "            fl = True\n",
    "            mass.append(i+2)\n",
    "            str1 =''\n",
    "            break                                                 \n",
    "    if fl == False: #  если слово не найдено, заменяем нулями\n",
    "        mass.append(0)\n",
    "        str1 =''\n",
    "\n",
    "    if len(mass)<len_text:  #  если слов меньше чем нужно, добавляем нулями.\n",
    "        while len(mass)<len_text:\n",
    "            mass.insert(0, 0)\n",
    "            str1 =''        \n",
    "        \n",
    "    return mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08146594-8a69-4b01-aa4a-fbfa940607df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd016a29-ad07-418c-99e1-69a800b956be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rating(num, data):\n",
    "    text_example = transform_text(data[num], vocab, 15)\n",
    "    print(text_example)\n",
    "    text_example1 = data[num]\n",
    "    print(text_example1[:150])\n",
    "    print('РЕЙТИНГ ФИЛЬМА: ', test_labels_1[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c320bda-20dc-4d05-b473-95af6d90f8cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 423, 82, 11, 17, 978, 4, 0, 406, 43, 87, 6, 27, 3152, 9]\n",
      "I went into this movie expecting a thoughtfull piece about how to be accepted in culture and I wound up blowing $8.50 on a 10 minute fart joke and a w\n",
      "РЕЙТИНГ ФИЛЬМА:  3\n"
     ]
    }
   ],
   "source": [
    "rating(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6053f68a-dfe2-480a-903a-fd505a3b2057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt = 'the end and and fgh I the open the open end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbe79b77-c975-41d3-9330-93928e0511fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 2, 129, 3, 3, 0, 10, 2, 940, 2, 940, 129]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example = transform_text(txt, vocab, 15)\n",
    "text_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ea71ea9-e10f-41f8-9a0d-5e80af54efbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 423, 82, 11, 17, 978, 4, 0, 406, 43, 87, 6, 27, 3152, 9]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example = transform_text(test_data_1[20000], vocab, 15)\n",
    "text_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cfc712f-ff56-4946-8c41-e9e9a19e37fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I went into this movie expecting a thoughtfull piece about how to be accepted in culture and I wound up blowing $8.50 on a 10 minute fart joke and a whole bunch of fake accents. Sorry, Jeff, but if you're going for the whole cult thing, you gotta a while to go.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_1[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c1dfbe-a3d8-42c2-a6c0-e1b91ba189dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_tensor = torch.tensor(text_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bddf1856-520d-4e92-bb9d-e413b3deb3c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  10,  423,   82,   11,   17,  978,    4,    0,  406,   43,   87,    6,\n",
       "          27, 3152,    9])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bed83c74-f62c-4562-b5fb-a5e3c3dcdf28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data, labels):\n",
    "    processed_data = []\n",
    "    \n",
    "    for text1 in data:  \n",
    "        text_list = transform_text(text1)\n",
    "        processed_data.append(text_list)\n",
    "\n",
    "    data_tensor = torch.tensor(processed_data)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    return data_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1646c9fb-21d2-4e34-b37d-678f705f92bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "list1 = [1, 2, 3]\n",
    "list2 = [4, 5, 6]\n",
    "\n",
    "list1 += list2\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f8a30-8a63-48ef-ab21-18a8bbb57528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a95189c-4f22-4ef9-aa59-7d737119b86b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_1(data_1, labels_1, data_2, labels_2):\n",
    "    processed_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for text1 in data_1:  \n",
    "        text_list = transform_text(text1)\n",
    "        processed_data.append(text_list)      \n",
    "    labels +=  labels_1  \n",
    "    \n",
    "    for text1 in data_2:  \n",
    "        text_list = transform_text(text1, rand=True)\n",
    "        processed_data.append(text_list)      \n",
    "    labels +=  labels_2  \n",
    "\n",
    "    data_tensor = torch.tensor(processed_data)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    return data_tensor, labels_tensor\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db06d4e6-4935-43ee-a00f-46b1d66163ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbbf759d-4742-4d53-88e8-d78dcf422fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rating_test(num):\n",
    "    \n",
    "    text_example = transform_text(test_data[num], vocab, 15)\n",
    "    print(text_example)\n",
    "    text_example1 = test_data[num]\n",
    "    print(text_example1[:150])\n",
    "    print('РЕЙТИНГ ФИЛЬМА: ', test_labels[num])\n",
    "    \n",
    "    print('Новые значения ')\n",
    "    print(test_data_tensor[num][:15])\n",
    "    print(test_labels_tensor[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28df4c-ade6-449e-b7f5-673a4fa46785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b4336-6eb3-4111-aba8-6a8dd2587ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=5, save_model_path='model_1.pth'):\n",
    "    train_losses = []  # Список для сохранения значений функции потерь на тренировочном наборе\n",
    "    val_losses = []  # Список для сохранения значений функции потерь на валидационном наборе\n",
    "    train_accuracies = []  # Список для сохранения значений точности на тренировочном наборе\n",
    "    val_accuracies = []  # Список для сохранения значений точности на валидационном наборе\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Обучение модели...\n",
    "\n",
    "        # Вычисление точности и потерь на тренировочном и валидационном наборах\n",
    "        train_accuracy, train_loss = compute_accuracy_and_loss(model, train_loader, criterion)\n",
    "        val_accuracy, val_loss = compute_accuracy_and_loss(model, val_loader, criterion)\n",
    "\n",
    "        # Сохранение значений точности и потерь\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Проверка, является ли текущая модель лучшей\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            # Сохранение модели\n",
    "            torch.save(model.state_dict(), save_model_path)\n",
    "\n",
    "    # Построение графиков точности и потерь\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(val_accuracies, label='Val Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Функция для вычисления точности и потерь\n",
    "def compute_accuracy_and_loss(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    loss = total_loss / len(data_loader)\n",
    "\n",
    "    return accuracy, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffac5c-77e7-4a90-b65a-984c2c309333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105dbc0f-c589-4c7f-9e1d-82e5e9b95283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e37f682-060c-496f-a61b-e198af302275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604209df-d0fc-4540-afb3-2125d35215a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40ee4840-13fc-4bea-afc4-b2a88905ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_train(num):\n",
    "    \n",
    "    text_example = transform_text(train_data[num], vocab, 15)\n",
    "    print(text_example)\n",
    "    text_example1 = train_data[num]\n",
    "    print(text_example1[:150])\n",
    "    print('РЕЙТИНГ ФИЛЬМА: ', train_labels[num])\n",
    "    \n",
    "    print('Новые значения ')\n",
    "    print(train_data_tensor[num][:15])\n",
    "    print(train_labels_tensor[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3298d8db-c5a7-4eac-9923-e4e061df1726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data1, test_labels1 = preprocess_data(test_data_1, test_labels_1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d89a0ebb-685b-4121-8cf3-4c3ed79a4f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(test_data1, 'test_data4.pt')\n",
    "torch.save(test_labels1, 'test_labels4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfdec1a-c18b-40c9-9c42-2ced1c145310",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc6e1b6-dcbf-4039-a23c-3b86c53cc547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192fac8b-5de2-45cd-8dd4-e816c3aeee93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb7e6ba-5745-4c1f-b2b8-3e84c54b0502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f5ae7e5-ec30-4b77-9019-b6480c7b0a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data1, train_labels1 = preprocess_1(train_data_1, train_labels_1, train_data_2, train_labels_2)\n",
    "\n",
    "torch.save(train_data1, 'train_data3.pt')\n",
    "torch.save(train_labels1, 'train_labels3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4191edc-c766-420d-b8d8-49896ef1335c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_tensor = torch.load('train_data3.pt')\n",
    "train_labels_tensor = torch.load('train_labels3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8457d1fd-6960-45b1-92f6-68b64e24e09c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65200"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6fc8a3f2-71a1-4268-8bb2-74e295136789",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65200"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ce9705e-40bc-4de2-a01b-0bb421ebff73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   11,\n",
      "           7,   33,  216,  281,   63,    5, 9841, 2980,    0,   34, 9946,    5,\n",
      "         110,   33,    0,   52,   23,    1,    0,  484,  353,    2,  573,    5,\n",
      "           0,   23,   13, 1480,    9, 1701,   93, 1621,    6, 3232,  115,   23,\n",
      "          13,    0,    1,    0,    3,   23, 4715,    0,    1,    0,    3,   23,\n",
      "        1043,    4,  265,   12,    0,    2,  675,    5, 3069,    2,  265,   13,\n",
      "           1,    0,    0,   18,   31,    2,  129,   23,  566,   25,  309,   12,\n",
      "          23,   13,   21,    4,  147,    0,    3,   53,   13,  463,   16,    8,\n",
      "           3,   23, 1091,   31,    2,  573,    5,    0,  107,  152,  100,   23,\n",
      "         423,  143,   82,    2])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_tensor[50000])\n",
    "print(train_labels_tensor[50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba2265-eca5-4a6d-a93d-9d7d34af6ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db0d2e-c06a-4f0f-8d6e-c3f4e8c9d25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e045a11-4af7-4611-baf9-a0c458c73b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tensor = torch.load('test_data3.pt')\n",
    "test_labels_tensor = torch.load('test_labels3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd6aad02-3223-4d95-9d43-217b28b7e2cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,   10,  187,  161,  102,    5,   28,   50,  213,    9,   11,    0,\n",
      "           2,   63,    7,  413,    0,    2,  111,    7,   14, 4407,   14,    4,\n",
      "           0,    3,    2,  223,    7,   37,   79,    8,  163,   22,  178,    6,\n",
      "         496,    0,  585,  463,   44,   22,  116,    0,   22,   26,    6,  116,\n",
      "           8,    6,    0,    0,   22,  230,  344,    8,    0,    0,   14,    8,\n",
      "          45, 1032, 3861,    3,   49,  633, 1069,   18,  936,   36,   12,    8,\n",
      "           7,    0,    8,   45,   49,  413,  365,  966,    3,    8,    7, 2709,\n",
      "          16,  192,  322,    3,  443,   77, 3436,  247,  385,    0,    2,   62,\n",
      "          59,   22,   78,  464,    7,   52,   22,   24, 1071,   31,    2, 2921,\n",
      "          41,   22,   24,  528, 2848,   15,    2,    0,   10,   26,  109,    4,\n",
      "         171,    5,  106,    3,   10,   26,    6,  133,   12,   11,    7,    2,\n",
      "         242,   19,   10,   26,  123,    0,   44,   22,   26,   11,   19,   10,\n",
      "          60, 1411,   22,  190,    8,  143,    6, 7753,   22, 1203,    8,   36,\n",
      "           3,   76,   22,  269])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_data_tensor[10])\n",
    "print(test_labels_tensor[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3d7c3-ed5b-4e61-a04b-7b3a9cdf8590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e571e13a-201e-443c-b633-385235fb4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных из файлов\n",
    "train_data_tensor = torch.load('train_data3.pt')\n",
    "train_labels_tensor = torch.load('train_labels3.pt')\n",
    "\n",
    "\n",
    "test_data_tensor = torch.load('test_data3.pt')\n",
    "test_labels_tensor = torch.load('test_labels3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180094d3-01dc-4d21-84aa-2e63d2db58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5eb5ab3e-c6a5-402c-80f0-26485ecd7fea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_data1, train_labels1 = preprocess_data(train_data, train_labels)\\nval_data1, val_labels1 = preprocess_data(val_data, val_labels)\\ntest_data1, test_labels1 = preprocess_data(test_data, test_labels)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_data1, train_labels1 = preprocess_data(train_data, train_labels)\n",
    "\n",
    "test_data1, test_labels1 = preprocess_data(test_data, test_labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "466ae104-0f35-415b-9525-5f59de64eeb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntorch.save(train_data1, 'train_data1.pt')\\ntorch.save(train_labels1, 'train_labels1.pt')\\ntorch.save(val_data1, 'val_data1.pt')\\ntorch.save(val_labels1, 'val_labels1.pt')\\ntorch.save(test_data1, 'test_data1.pt')\\ntorch.save(test_labels1, 'test_labels1.pt')\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохранение данных в файлы\n",
    "'''\n",
    "torch.save(train_data1, 'train_data1.pt')\n",
    "torch.save(train_labels1, 'train_labels1.pt')\n",
    "torch.save(val_data1, 'val_data1.pt')\n",
    "torch.save(val_labels1, 'val_labels1.pt')\n",
    "torch.save(test_data1, 'test_data1.pt')\n",
    "torch.save(test_labels1, 'test_labels1.pt')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04626e16-0743-4da1-a9e7-aaf68ebd90bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Загрузка данных из файлов\n",
    "train_data_tensor = torch.load('train_data1.pt')\n",
    "train_labels_tensor = torch.load('train_labels1.pt')\n",
    "val_data_tensor = torch.load('val_data1.pt')\n",
    "val_labels_tensor = torch.load('val_labels1.pt')\n",
    "test_data_tensor = torch.load('test_data1.pt')\n",
    "test_labels_tensor = torch.load('test_labels1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71d6b2-00a0-4fbf-918d-c4b48e600434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf37be1e-e5b8-488b-8d21-79aa2843f4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_labels_tensor = [label - 1 if label <= 4 else label - 3 for label in train_labels_tensor]\\nval_labels_tensor = [label - 1 if label <= 4 else label - 3 for label in val_labels_tensor]\\ntest_labels_tensor = [label - 1 if label <= 4 else label - 3 for label in test_labels_tensor]\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Преобразование меток классов\n",
    "'''\n",
    "train_labels_tensor = [label - 1 if label <= 4 else label - 3 for label in train_labels_tensor]\n",
    "val_labels_tensor = [label - 1 if label <= 4 else label - 3 for label in val_labels_tensor]\n",
    "test_labels_tensor = [label - 1 if label <= 4 else label - 3 for label in test_labels_tensor]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d485f369-6322-48fe-b8c6-8628e5b01c21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drug1\\AppData\\Local\\Temp\\ipykernel_14116\\3457568113.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels_tensor = torch.tensor(train_labels_tensor)\n",
      "C:\\Users\\drug1\\AppData\\Local\\Temp\\ipykernel_14116\\3457568113.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_labels_tensor = torch.tensor(val_labels_tensor)\n",
      "C:\\Users\\drug1\\AppData\\Local\\Temp\\ipykernel_14116\\3457568113.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_labels_tensor = torch.tensor(test_labels_tensor)\n"
     ]
    }
   ],
   "source": [
    "train_labels_tensor = torch.tensor(train_labels_tensor)\n",
    "train_labels_tensor = torch.where(train_labels_tensor <= 4, train_labels_tensor - 1, train_labels_tensor - 3)\n",
    "\n",
    "val_labels_tensor = torch.tensor(val_labels_tensor)\n",
    "val_labels_tensor = torch.where(val_labels_tensor <= 4, val_labels_tensor - 1, val_labels_tensor - 3)\n",
    "\n",
    "test_labels_tensor = torch.tensor(test_labels_tensor)\n",
    "test_labels_tensor = torch.where(test_labels_tensor <= 4, test_labels_tensor - 1, test_labels_tensor - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66805cdd-0fee-49c1-8c2a-e42121569cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13312"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be97ea8f-b088-4d95-9aef-d45effedf85c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4688"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36a58b16-b79d-4337-aca1-06ebec379fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be040039-754c-4300-9615-6dc7a38be317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[31000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8cd62112-b426-4283-ae7e-60555a8eb7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_tensor[31000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2cb8be62-a29f-4283-b7e1-57e249ca7e92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_tensor[6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a66c7f07-40f5-4861-895c-692c3136dfbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s remarkable and quite praiseworthy how writers and directors continue to make great movies out of one of the oldest and most (over)used story lines in cinema! \"Dog Bite Dog\" is basically not much more than just the simple story of an lone copper obsessively chasing a brilliant criminal, only Pou-Soi Cheang distinguishes his film from the rest by being extremely violent & relentless. This is unquestionably one of the grittiest and most uncompromising movies I\\'ve ever seen, with an atmosphere of constant nihilism and characters that seem to come walking straight out of hell! Not even the installments in Chan-Wook Park\\'s trilogy of vengeance (with the exception of \"Oldboy\", perhaps) or any other infamous Cat-III film ever released were as sadistic and brutal as some of the events depicted in \"Dog Bite Dog\". Pang is a young and ruthless Cambodian assassin who lands in the crowded streets of Hong Kong to eliminate the wife of an eminent judge in a restaurant. When the police arrives at the place, young officer Wai sees how Pang hastily flees from the scene of the crime and follow him. The first actual confrontation between the two rabid dogs results in a gigantic blood bath, as Pang mercilessly kills several hostages and even Wai\\'s long time friend and colleague. From then on begins a thrilling and action-packed cat and mouse game between the frustrated cop and the professional killer. The latter also saves a young girl from the constant sexual abuse of her father and stays with her at her shed in the local garbage dump. What makes this routine action/thriller so fascinating (apart from the explicit violence) are the main characters\\' backgrounds! Pang, the hit-man, is a Cambodian orphan and has been trained to fight & kill for money ever since he was a child. He knows no restrictions, has no mercy and barely speaks a word. Wai, the cop, became particularly ruthless and unorthodox ever since his role-model father (also a cop) lies in a coma after a drug-related incident. Lai doesn\\'t question suspects and witnesses; he yells at them and he\\'s prepared to sacrifice everything in order to stop his brand new nemesis. People with a weak stomach or tangled nerves are advised to stay away from this film, because the cruelty and shocks featuring in \"Dog Bite Dog\" can easily cause nausea. It\\'s not the type of violence where bloodied heads and chopped off limbs fly through the air, but more like the intense and utterly disturbing type where people attempt to crush their opponents mentally as well as physically. The filming locations are effectively dark and eerie and the extremely sober music makes the already harrowing tone of the movie even more petrifying. The performances are terrific! I wouldn\\'t be surprised if Edison Chen and Sam Lee treated each other like enemies on the film set as well, because their on screen hatred and disgust feels a little too legitimate. \"Dog Bite Dog\" is a powerful and unforgettable film, highly recommended if you can stomach it. If you fear you can\\'t, just wait a few years for the inevitable American remake which will unquestionably soften the premise a little.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3f0b406-6065-404d-9648-6d4f24861d67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 1677,    2,  176,    0,   86,  893,    2,  872, 1685,    5,   95,\n",
       "          84,  100,   45,    4,   27,    4,    1, 5439,    2,   88,    0,   62,\n",
       "         398,    8,    0,    0, 3872,    0,    6,  669,   20,   73,   50,   71,\n",
       "          41,    1,  588,   62,    4,   32, 4708,    0,    0, 3270,    3,  510,\n",
       "           0,   61,    0,    0,    0,   24,   18,   35,    1,  349,   31,  109,\n",
       "         556, 1099,    0,    0,   10,    6,    0,   27,    4,    1,    0,    2,\n",
       "          88,    0,  100,  198,  122,    0,   15,   32,  810,    4, 1766,    0,\n",
       "           2,  102,   11,  297,    5,  211, 1254,  791,   45,    4,    0,   20,\n",
       "          54,    1,    0,    8,    0,    0, 2302,    4, 4445,    0,    1, 1345,\n",
       "           4,    0,    0,   40,   98,   79, 3065,    0,   18,  122,  616,   68,\n",
       "          13, 3876,    2, 1719,   13,   48,    4,    1,  665, 2320,    8,    0,\n",
       "        3872,    0,    0,    6,    3,  180,    2, 4191,    0, 4824,   33, 5220,\n",
       "           8,    1, 8372, 1884,    4, 2514, 1937,    5, 9439,    1,  308,    4,\n",
       "          32,    0, 1819,    8,    3,    0,   51,    1,  547, 2863,   30,    1,\n",
       "           0,  180, 1816,    0, 1044,   86,    0,    0,    0,   35,    1,  133,\n",
       "           4,    1,  822,    2,  819,    0,    1,   85,  750, 5039,  195,    1,\n",
       "         106, 9811, 2445, 1846,    8,    3, 7274,  525])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_tensor[30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ba9a0-0d10-42e7-8e15-86c3c9e27ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f944d86-51ae-4d21-96c7-13bcd5447cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Датасеты\n",
    "train_dataset = torch.utils.data.TensorDataset(train_data_tensor.clone().detach(), train_labels_tensor.clone().detach())\n",
    "val_dataset = torch.utils.data.TensorDataset(val_data_tensor.clone().detach(), val_labels_tensor.clone().detach())\n",
    "test_dataset = torch.utils.data.TensorDataset(test_data_tensor.clone().detach(), test_labels_tensor.clone().detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0552fb1c-82d2-49cf-a204-b9fb79fd9995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Создание итераторов для загрузки данных\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
